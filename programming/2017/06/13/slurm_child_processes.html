<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>Slurm and disappearing jobs: parallel processes in non-terminal environments - Genomics in B♭</title>
    <meta name="description" content="Biology, programming, music.">
    <link rel="stylesheet" href="/css/picnic.min.css">
    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/pygments.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
  </head>

  <body>
    
      <header>
      <nav>
        <a href="/" class="brand">
            <img src="/img/mwhamgenomics.png" width="20" height="20" />
            Genomics in B<span class="music">♭</span>
        </a>

        <input id="minimenu" type="checkbox" class="show">
        <label for="minimenu" class="burger pseudo button"><img class="icon_large" src="/img/menu.svg" /></label>

        <div class="menu">
          <a href="/archive">All posts</a>
          <a href="/bioinformatics">Bioinformatics</a>
          <a href="/programming">Programming</a>
          <a href="/music">Music</a>
          <span class="divider"></span>
          <a href="/tags">Tags</a>
          <a href="/linux">Linux reference</a>
        </div>

      </nav>
    </header>
    

    <div class="flex one two-800">
      <div class="three-fourth-800">
<h2>Slurm and disappearing jobs: parallel processes in non-terminal environments</h2>

<p>13 Jun 2017</p>



<p>Category: <a href="/programming">programming</a></p>



<p>Tags: <span>
  
    <a href="/tags#bash">bash</a>, 
  
    <a href="/tags#linux">linux</a>
  
</span></p>


<p>Lately, I've been puzzling over a problem with
<a href="/bioinformatics/2016/10/14/filtering_fastq_reads.html">our fastq filtering process</a> at work. We recently added a new
feature to our <a href="http://github.com/EdinburghGenomics/Fastq-Filterer">fastq filterer</a> to write a text file with statistics
of the data processing performed. When we ran this new version in production, though, we found that sometimes this stats
file was not being written, even though the Slurm job running it was returning a 0 exit status. This prompted a lengthy
investigation that has been my primary source of annoyance over the past few weeks and made me question my own technical
ability (and sanity) at various points, but taught me something useful in the end when I finally figured out the
problem.</p>
<h2>Debugging</h2>
<p>My first idea was to check the fastq filterer itself for bugs - I wrote it after all, and I'm not that experienced with
C. After a thorough debugging session with <a href="/programming/2017/05/22/valgrind.html">Valgrind</a>, I had much tidier memory
management and reassurance that my C programming abilities aren't as shabby as I initially feared (in hindsight, how
complicated and error-prone can writing to a file stream be?). I still had no answer, though, and I had to be sure that
the randomly-disappearing stats files were not due to a problem in the script.</p>
<h2>Reimplementation</h2>
<p>I tried re-implementing the filterer in Python, and the problem remained. This acquitted the filterer of any wrongdoing.
I then tried adding some debugging <code>print</code> statements into the script, and found something interesting: whenever a stats
file failed to write, I was also getting print statements failing to work. It seemed that either the IO was getting cut
off, or the job was getting killed.</p>
<p>I tried running this re-implemented script with <code>python -v</code>, which prints extra information about what the interpreter
is doing. Surprisingly, whenever I got a failing stats file and print statements, I also got none of the cleanup
messages I expected from the interpreter at the end of execution. Not only was the script seemingly getting stopped, the
entire Python interpreter was crashing silently! Clearly something funny was going on here, and it wasn't bugs in my
code.</p>
<h2>Narrowing it down</h2>
<p>Since stats files were only failing to write occasionally, my boss suggested that it was a race condition. Race
conditions occur when concurrent threads or processes don't complete in the correct order - two threads 'race' to
completion and if the wrong one finishes first, weird things happen. I tried putting some <code>sleep</code> statements around the
code that wrote the stats file, which made the problem occur every single time. This may not sound like an improvement,
but we are now one step closer to identifying the problem.</p>
<p>The next step was to eliminate more factors from the environment in which we were running the fastq filtering. The
problem did not occur in a plain Bash session, so it was something to do with Slurm. The script was being called inside
a complex bit of Bash syntax including the use of <code>set -e</code>, the removal of which did not affect anything. Our filtering
process made use of <a href="/programming/2016/11/28/bash_io.html">Unix named pipes</a> for GZ compression of output data on the
fly, and if we removed this, the problem did not occur. When we tried moving all <code>fclose()</code> calls to the very end of the
filter script, the problem also did not occur. At this point, it looked like the problem was something to do with the
way Slurm handles the closing of named pipes (although it turned out not to be).</p>
<h2>A minimal test</h2>
<p>The race condition and the parallel processes seemingly getting killed indicated that it could be a problem with named
pipes, or a problem with concurrent child processes in general. Just to be sure that the problem wasn't caused by us
before getting angry at our sysadmins, we tried a very minimal test case, consisting of a Python script run under Slurm:</p>
<p>test_concurrency.py:</p>
<div class="code"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">sleep</span><br />&nbsp;<br /><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Writing some data to f1&#39;</span><span class="p">)</span><br /><span class="n">f1</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;f1.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span><br /><span class="n">f1</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;some data</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span><br /><span class="n">f1</span><span class="o">.</span><span class="n">close</span><span class="p">()</span><br /><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;f1 done&#39;</span><span class="p">)</span><br /><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><br />&nbsp;<br /><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Writing some more data to f2&#39;</span><span class="p">)</span><br /><span class="n">f2</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;f2.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span><br /><span class="n">f2</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;some more data</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span><br /><span class="n">f2</span><span class="o">.</span><span class="n">close</span><span class="p">()</span><br /><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;f2 done&#39;</span><span class="p">)</span><br /></pre></div><br /></div>

<p>test_concurrency.slurm:</p>
<div class="code"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span><br /><span class="c1">#SBATCH --job-name=&quot;test_concurrency&quot;</span><br /><span class="c1">#SBATCH --cpus-per-task=1</span><br /><span class="c1">#SBATCH --mem=2g</span><br /><span class="c1">#SBATCH --output=path/to/test_concurrency.slurm.log</span><br />&nbsp;<br /><span class="k">function</span> test_concurrency <span class="o">{</span><br />    <span class="nb">echo</span> <span class="s2">&quot;[slurm script] Starting&quot;</span><br />    python test_concurrency.py &gt; concurrency_test.log<br />    <span class="nb">echo</span> <span class="s2">&quot;[slurm script] Done&quot;</span><br /><span class="o">}</span><br />&nbsp;<br /><span class="c1"># test case 1: single command only</span><br />test_concurrency<br />&nbsp;<br /><span class="c1"># test case 2: running the script as a child process</span><br />test_concurrency <span class="p">&amp;</span> <span class="nb">echo</span> <span class="s2">&quot;Doing some other stuff&quot;</span><br /></pre></div><br /></div>

<p>When we ran this with test cases 1 and 2 alternately commented in/out, we found that test case 1 worked fine, but test
case 2 failed to write files, and there was no <code>'[slurm script] Done'</code> echoed into the Slurm log file. We then found
that adding a <code>wait</code> statement in the Slurm script after starting the two concurrent jobs solved it. At last we had
found the problem!</p>
<h2>The race condition explained</h2>
<p>In this case, the problem was a result of using Bash child processes incorrectly in a non-terminal environment (in this
case, Slurm). In test case 2, we kicked off a <code>test_concurrency</code> function in the background and then echoed a string to
stdout in the foreground. Once the <code>echo</code> has run, as far as Slurm is concerned, the script has completed, even though
the Python process is still running. Slurm then stops executing and closes the parent Bash process, cutting off any
child processes. This did not happen with my tests in an interactive Bash session because there is no cut-off point for
completion of child processes in a long-running interactive terminal.</p>
<p>Let's apply this to the situation we had with the fastq filterer:</p>
<div class="code"><div class="highlight"><pre><span></span>mkfifo r1_filtered.fastq<span class="p">;</span> mkfifo r2_filtered.fastq<br />./fastq_filterer --threshold <span class="m">36</span> --i1 r1.fastq.gz --i2 r2.fastq.gz --o1 r1_filtered.fastq --o2 r2_filtered.fastq <span class="p">&amp;</span><br />pigz -c r1_filtered.fastq &gt; r1_filtered.fastq.gz <span class="p">&amp;</span><br />pigz -c r2_filtered.fastq &gt; r2_filtered.fastq.gz<br /></pre></div><br /></div>

<p>Here, we kick off the filterer and a pigz in the background, and another pigz in the foreground. The filterer will
process its inputs, writing to the <code>fifo</code> named pipes and closing them when it's finished. At this point, the two pigz
processes will complete. Now because the foreground pigz has finished, Slurm exits, cutting off the filterer, even if
it's still busy writing its stats file. This explains both the missing stats files and why moving the <code>fclose()</code> calls
to the end of the script fixed it (they essentially delayed the exiting of the foreground pigz).</p>
<h2>The fix</h2>
<p>All we need to do in this case is explicitly wait for all child processes to finish. This is possible with a Bash
command aptly called <code>wait</code>:</p>
<div class="code"><div class="highlight"><pre><span></span>./fastq_filterer --threshold <span class="m">36</span> --i1 r1.fastq.gz --i2 r2.fastq.gz --o1 r1_filtered.fastq --o2 r2_filtered.fastq <span class="p">&amp;</span><br />pigz -c r1_filtered.fastq &gt; r1_filtered.fastq.gz <span class="p">&amp;</span><br />pigz -c r2_filtered.fastq &gt; r2_filtered.fastq.gz <span class="p">&amp;</span>  <span class="c1"># we can now run everything as a child process</span><br /><span class="nb">wait</span>  <span class="c1"># with no arguments, this will wait for all child processes</span><br /></pre></div><br /></div>

<p>The addition of a simple four-character command at the end of the script does solve the problem, but we wanted to be
able to look at the exit status of each child process. To do this, we would need to capture the pid of each process with
<code>$!</code> and wait on them explicitly:</p>
<div class="code"><div class="highlight"><pre><span></span>./fastq_filterer --threshold <span class="m">36</span> --i1 r1.fastq.gz --i2 r2.fastq.gz --o1 r1_filtered.fastq --o2 r2_filtered.fastq <span class="p">&amp;</span><br /><span class="nv">fq_filt_pid</span><span class="o">=</span><span class="nv">$!</span><br />pigz -c r1_filtered.fastq &gt; r1_filtered.fastq.gz <span class="p">&amp;</span><br /><span class="nv">pigz_r1_pid</span><span class="o">=</span><span class="nv">$!</span><br />pigz -c r2_filtered.fastq &gt; r2_filtered.fastq.gz <span class="p">&amp;</span>  <span class="c1"># we can now run everything as a child process</span><br /><span class="nv">pigz_r2_pid</span><span class="o">=</span><span class="nv">$!</span><br />&nbsp;<br /><span class="nb">wait</span> <span class="nv">$fq_filt_pid</span>  <span class="c1"># wait returns the exit status of the pid specified</span><br /><span class="nv">fq_filt_exit_status</span><span class="o">=</span><span class="nv">$?</span><br /><span class="nb">wait</span> <span class="nv">$pigz_r1_pid</span><br /><span class="nv">pigz_r1_exit_status</span><span class="o">=</span><span class="nv">$?</span><br /><span class="nb">wait</span> <span class="nv">$pigz_r2_pid</span><br /><span class="nv">pigz_r2_exit_status</span><span class="o">=</span><span class="nv">$?</span><br /></pre></div><br /></div>

<p>It doesn't matter which order you wait for the pids, because you can still call <code>wait</code> on a child process after it's
finished, and even call it multiple times. I couldn't find any discussion of this subject online, so hopefully this will
be an aid to anyone encountering problems with parallel processes within distributed compute jobs. To conclude:</p>
<ul>
<li>To find the cause of a problem, try to eliminate as many external factors as possible from your testing</li>
<li>When you encounter a particularly confusing problem such as this one, the solution is often extremely simple</li>
<li>When something randomly fails, it may be a race condition, in which case <code>sleep</code> statements can be useful in finding
  the cause</li>
<li>Always wait on your child processes.</li>
</ul>

<h3>External links</h3>



<p>
  Previous post:
  
    <a class="post-meta" href="/programming/2017/05/22/valgrind.html">Debugging C programs with Valgrind</a>
  
</p>

<p>
  Next post:
  
    <a class="post-meta" href="/programming/2018/01/22/web_app_5_https.html">Building a web app part 5 - Running Apache on HTTPS</a>
  
</p>


</div>

      
      <div class="fourth-800">
        <div class="sidebar">
          <h4>Genomics in B♭</h4>
          <p>
            <i class="fa fa-flask"></i> Biology<br/>
            <i class="fa fa-terminal"></i> Programming<br/>
            <i class="fa fa-music"></i> Music
          </p>

          <p>
            Built with <a href="https://python-markdown.github.io">Python-Markdown</a> and
            <a href="https://jinja.palletsprojects.com">Jinja2</a>. Styled with
            <a href="https://pygments.org">Pygments</a>, <a href="https://picnicss.com">Picnic CSS</a> and
            <a href="https://fontawesome.com">Font Awesome</a>. Hosted on
            <a href="https://pages.github.com">GitHub Pages</a>.
          </p>
          <a href="https://www.github.com/mwhamgenomics"><i class="fa fa-github"></i> mwhamgenomics</a>
        </div>
      </div>
      

    </div>

    
    <footer>
        <p>© http://github.com/mwhamgenomics</p>
    </footer>
    

  </body>

</html>